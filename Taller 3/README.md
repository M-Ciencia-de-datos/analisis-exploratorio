# üåô Taller 3: An√°lisis Exploratorio Bivariado üí§

## Integrantes:

- Katherin Escobar
- Heberth Martinez
- Diana Mazuera
- Natalia Santamaria

## Introducci√≥n

La base de datos de "Ciclo de sue√±o y productividad" analiza los h√°bitos de sue√±o y su impacto en la productividad, el estado de √°nimo y los niveles de estr√©s.

Se cuenta con 5000 registros que abarcan personas entre los 18 y 60 a√±os de edad y sus distintos estilos de vida.

A continuaci√≥n, est√° la descripci√≥n de cada columna de la base de datos:

![Data](assets/Data_descrip.PNG)

## Pregunta SMART

¬øQu√© impacto tiene el total de horas de sue√±o en la productividad de los trabajadores?

## Selecci√≥n de variables

El an√°lisis realizado se hizo con el fin de identificar la caracter√≠stica que tuviera una mayor relaci√≥n con la variable objetivo "Productivity Score", por lo que se empez√≥ una revisi√≥n de la base de datos detectando que estamos frente a un problema de clasificaci√≥n con variables no lineales, y no se cuentan con datos at√≠picos, nulos o faltantes.

## Importancia de las variables

En la din√°mica actual, donde la tecnolog√≠a y el ritmo acelerado dominan las rutinas, es crucial mantener la productividad y el bienestar. Teniendo en cuenta diferente literatura se observa que el sue√±o y el ejercio son fundamentales para la salud humana, afectando no solo el bienestar f√≠sico sino tambi√©n la capacidad mental y cognitiva. Autores como Dement y Vaughan (1999), Van Dongen y otros (2003), Turner y otros (2007) demuestran que el sue√±o se relaciona con el desempe√±o cognitivo, la toma de decisiones, el razonamiento, la memoria, la soluci√≥n de problemas, la atenci√≥n e incluso los accidentes.

Tomando en cuenta no solo la literatura previa, sino tambi√©n la correlaci√≥n de los datos, se determina que las mejores caracter√≠sticas son "Total Sleep Hours" y "Exercise".

## Descripcion del c√≥digo

<a target="_blank" href="https://colab.research.google.com/github/M-Ciencia-de-datos/analisis-exploratorio/blob/main/Taller%202/notebook.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

### Resumen del An√°lisis de Datos y Modelado con Regularizaci√≥n

#### Carga y Exploraci√≥n del Dataset

En la primera secci√≥n, se carga el conjunto de datos en un `DataFrame` de `pandas`. Posteriormente, se realiza una exploraci√≥n preliminar que incluye:

- Visualizaci√≥n de las primeras filas con `df.head()`.
- Inspecci√≥n de la estructura del dataset con `df.info()`.
- C√°lculo de estad√≠sticas descriptivas con `df.describe()`.
- Detecci√≥n de valores nulos mediante `df.isnull().sum()`.

Esto permite obtener una comprensi√≥n inicial de las caracter√≠sticas y posibles problemas del dataset.

#### An√°lisis Exploratorio de Datos

Se emplean diversas t√©cnicas de visualizaci√≥n para entender la distribuci√≥n de los datos y sus relaciones:

1. **Pairplot con Seaborn**: Se genera un `sns.pairplot(df)` para visualizar la distribuci√≥n de variables y su relaci√≥n entre s√≠.
2. **Box Plot Interactivo con Plotly**: Se usa `plotly.express.box()` para representar la distribuci√≥n de cada variable de manera interactiva.

#### C√°lculo de Correlaciones y Selecci√≥n de Variables Relevantes

Se utiliza la correlaci√≥n de Pearson para medir la relaci√≥n entre las variables y la variable objetivo. El proceso es el siguiente:

- Se calcula la matriz de correlaci√≥n con `df.corr()`.
- Se genera un `heatmap` con `seaborn` para visualizar los coeficientes de correlaci√≥n.
- Se identifican las dos variables con mayor correlaci√≥n con la variable objetivo.

#### Normalizaci√≥n y Revisi√≥n de Correlaciones

Para evaluar c√≥mo afecta la normalizaci√≥n a la correlaci√≥n de las variables, se aplican dos m√©todos de escalado:

1. **StandardScaler**: Normaliza los datos a una distribuci√≥n con media 0 y desviaci√≥n est√°ndar 1.
2. **MinMaxScaler**: Escala los datos en un rango de 0 a 1.

Despu√©s de la normalizaci√≥n, se recalcula la matriz de correlaci√≥n para analizar posibles cambios.

#### An√°lisis Estad√≠stico Descriptivo

Se calculan diversas m√©tricas estad√≠sticas, incluyendo:

- Media y mediana.
- Moda y percentiles.
- Rango intercuart√≠lico.

Estas estad√≠sticas ayudan a comprender la dispersi√≥n y distribuci√≥n de los datos.

#### Modelado con Regresi√≥n Log√≠stica Regularizada

Se implementa una **regresi√≥n log√≠stica con ElasticNet y validaci√≥n cruzada** (`LogisticRegressionCV`) para evaluar la importancia de las variables. El flujo es el siguiente:

1. **Divisi√≥n en conjunto de entrenamiento y prueba** usando `train_test_split()` con `stratify=y`.
2. **Normalizaci√≥n de datos** mediante `StandardScaler`.
3. **Entrenamiento del modelo** con regularizaci√≥n ElasticNet (`penalty='elasticnet'`, `solver='saga'`).
4. **Evaluaci√≥n de la precisi√≥n del modelo** con `accuracy_score()`.
5. **Extracci√≥n de los coeficientes** para identificar las variables m√°s relevantes.

### Resumen del An√°lisis de Datos y Modelado con Regularizaci√≥n

#### Carga y Exploraci√≥n del Dataset

En la primera secci√≥n, se carga el conjunto de datos en un `DataFrame` de `pandas`. Posteriormente, se realiza una exploraci√≥n preliminar que incluye:

- Visualizaci√≥n de las primeras filas con `df.head()`.
- Inspecci√≥n de la estructura del dataset con `df.info()`.
- C√°lculo de estad√≠sticas descriptivas con `df.describe()`.
- Detecci√≥n de valores nulos mediante `df.isnull().sum()`.

Esto permite obtener una comprensi√≥n inicial de las caracter√≠sticas y posibles problemas del dataset.

#### An√°lisis Exploratorio de Datos

Se emplean diversas t√©cnicas de visualizaci√≥n para entender la distribuci√≥n de los datos y sus relaciones:

1. **Pairplot con Seaborn**: Se genera un `sns.pairplot(df)` para visualizar la distribuci√≥n de variables y su relaci√≥n entre s√≠.
2. **Box Plot Interactivo con Plotly**: Se usa `plotly.express.box()` para representar la distribuci√≥n de cada variable de manera interactiva.

#### C√°lculo de Correlaciones y Selecci√≥n de Variables Relevantes

Se utiliza la correlaci√≥n de Pearson para medir la relaci√≥n entre las variables y la variable objetivo. El proceso es el siguiente:

- Se calcula la matriz de correlaci√≥n con `df.corr()`.
- Se genera un `heatmap` con `seaborn` para visualizar los coeficientes de correlaci√≥n.
- Se identifican las dos variables con mayor correlaci√≥n con la variable objetivo.

#### Normalizaci√≥n y Revisi√≥n de Correlaciones

Para evaluar c√≥mo afecta la normalizaci√≥n a la correlaci√≥n de las variables, se aplican dos m√©todos de escalado:

1. **StandardScaler**: Normaliza los datos a una distribuci√≥n con media 0 y desviaci√≥n est√°ndar 1.
2. **MinMaxScaler**: Escala los datos en un rango de 0 a 1.

Despu√©s de la normalizaci√≥n, se recalcula la matriz de correlaci√≥n para analizar posibles cambios.

#### An√°lisis Estad√≠stico Descriptivo

Se calculan diversas m√©tricas estad√≠sticas, incluyendo:

- Media y mediana.
- Moda y percentiles.
- Rango intercuart√≠lico.

Estas estad√≠sticas ayudan a comprender la dispersi√≥n y distribuci√≥n de los datos.

#### Modelado con Regresi√≥n Log√≠stica Regularizada

Se implementa una **regresi√≥n log√≠stica con ElasticNet y validaci√≥n cruzada** (`LogisticRegressionCV`) para evaluar la importancia de las variables. El flujo es el siguiente:

1. **Divisi√≥n en conjunto de entrenamiento y prueba** usando `train_test_split()` con `stratify=y`.
2. **Normalizaci√≥n de datos** mediante `StandardScaler`.
3. **Entrenamiento del modelo** con regularizaci√≥n ElasticNet (`penalty='elasticnet'`, `solver='saga'`).
4. **Evaluaci√≥n de la precisi√≥n del modelo** con `accuracy_score()`.
5. **Extracci√≥n de los coeficientes** para identificar las variables m√°s relevantes.

## Interpretacion

El an√°lisis se divide en tres etapas. La primera etapa, se enfoca en comprender las relaciones lineales entre diversas variables y la puntuaci√≥n de productividad. Se observ√≥ que variables como las horas de sue√±o total, el ejercicio y la ingesta de cafe√≠na presentaban correlaciones d√©biles con la productividad, sugiriendo, que, por s√≠ solas, no logran predecir, de manera lineal la productividad.

Para profundizar en el estudio, se analizaron gr√°ficos de dispersi√≥n que representaban la relaci√≥n entre "Exercise (mins/day)" y "Productivity Score", as√≠ como entre "Total Sleep Hours" y "Productivity Score". En ambos casos, se observ√≥ una falta de correlaci√≥n lineal, reforzando la idea de que ni la cantidad de ejercicio ni la cantidad de sue√±o, por s√≠ solas, son determinantes clave de la productividad en el trabajo. Estos resultados sugieren que otros factores podr√≠an estar influyendo en la productividad.

En la segunda etapa, se aplicaron t√©cnicas de normalizaci√≥n de datos para evaluar cambios en los valores de las variables y su impacto en la correlaci√≥n. Al comparar la matriz de correlaci√≥n normalizada con la matriz de correlaci√≥n original, se nota que las correlaciones entre la productividad y el ejercicio, as√≠ como entre la productividad y las horas de sue√±o, se mantienen despu√©s de la normalizaci√≥n. Lo anterior, refuerza la idea de que estas variables no tienen una relaci√≥n lineal fuerte con la productividad. Adem√°s, los valores de correlaci√≥n no experimentaron cambios significativos que alteraran las conclusiones principales, lo que indica que las relaciones entre las variables son ‚Äúrobustas‚Äù y no se ven afectadas significativamente por la escala de los datos.

Por √∫ltimo, en la tercera etapa, se utiliz√≥ un modelo de Regresi√≥n Log√≠stica con ElasticNet y validaci√≥n cruzada para identificar las variables m√°s relevantes en la predicci√≥n de la variable objetivo. El modelo ElasticNet seleccion√≥ "Screen Time Before Bed (mins)" y "Total Sleep Hours" como las variables m√°s importantes para predecir la productividad. Sin embargo, la precisi√≥n del modelo en el conjunto de prueba fue del 11%, lo que sugiere que, aunque estas variables tienen cierto impacto, el modelo lineal no captura completamente la relaci√≥n. La baja precisi√≥n del modelo indica que se necesitan enfoques adicionales para mejorar la predicci√≥n de la variable objetivo.

## Hip√≥tesis
Ho: No hay relaci√≥n entre las horas de sue√±o y la productividad
Ha: si existe alguna relaci√≥n entre las horas de sue√±o y la productividad

## Tabla de contingencia

| **Sleep Hours** | **Poor** | **Average** | **Good** | **Excelent** |
| :-------------: | :------: | :---------: | :------: | :----------: |
|     4.5-5.6     |   354    |     393     |   235    |     269      |
|     5.6-6.9     |   366    |     373     |   250    |     275      |
|     6.9-8.2     |   342    |     355     |   265    |     278      |
|     8.2-9.5     |   366    |     334     |   268    |     277      |

## üìå Conclusiones

1Ô∏è‚É£La relaci√≥n entre los patrones de sue√±o y la productividad parece ser m√°s compleja de lo que se supon√≠a en un principio, se podr√≠a considerar incluir otras caracter√≠sticas relevantes (ej H√°bitos alimenticios, entorno de trabajo, satisfacci√≥n laboral)

